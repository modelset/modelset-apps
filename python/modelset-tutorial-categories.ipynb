{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelSet - Basic tutorial\n",
    "\n",
    "ModelSet is a dataset of software models originally intented to help in the application of machine learning techniques to solve modelling tasks.\n",
    "\n",
    "In this tutorial we will explain how to load the dataset and extract basic features to perform a classification task: inferring the category of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First of all, you need to download and install ModelSet. \n",
    "\n",
    " 1. Download the package containing the raw models and the associated databases. Available at http://modelset.github.io/download/current.\n",
    " 2. Unzip the package\n",
    " 3. Make sure that the variable (see below) MODELSET_HOME points to the location in which you unzipped the package\n",
    " 4. Install the python library using pip\n",
    "    * pip install modelset-py\n",
    "    * If you have downloaded the source code of the library from http://github.com/modelset/modelset-py ,\n",
    "      then use `sys.path.append(\"/path/to/modelset-py/src\")` as a shortcut to load it dynamically.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do change this path to fit your local installation\n",
    "MODELSET_HOME=\"/path/to/modelset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "The ModelSet library offers a convenient interface to dump the contents of the underlying database into a dataframe. In particular, there are several features available in the output dataframe:\n",
    "\n",
    " * The identifier of the model\n",
    " * The category of the model (manually labelled). Reflects the domain of the model.\n",
    " * Associated tags (zero or more manually labelled) which provide additional insights about the type of model.\n",
    " * The language of the model (typically english)\n",
    " * Basic stats. In the case of Ecore, number of elements, references, classes, attributes, packages, enumerations and datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#sys.path.append(\"/path/to/modelset/modelset-py/src\")\n",
    "import modelset.dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ds.load(MODELSET_HOME, modeltype = 'ecore', selected_analysis = ['stats'])\n",
    "# You can just use: ds.load(MODELSET_HOME, modeltype = 'ecore') to speedup the loading if you don't need the stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataset into a Pandas dataframe. There are two methods: \n",
    " * `to_df()` converts the complete dataset. \n",
    " * `to_normalized_df()` only considers examples with a minimum number of examples (7 by default), written in english and removing special categories (dummy and unknown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelset_df = dataset.to_normalized_df()\n",
    "# You can configure the elements of the dataframe:\n",
    "# modelset_df = dataset.to_normalized_df(min_ocurrences_per_category = 7, languages = ['english'], remove_categories = ['dummy', 'unknown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset\n",
    "\n",
    "To train our model we are interested on the category attribute, which will be our target variable (the label that we want to predict) and we are going to use the model identifiers as input data because we will use them to lookup the corresponding textual representation (see below). \n",
    "\n",
    "We need to split our dataset into training and test, so that we can evaluate later the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# These dataframes are vectors\n",
    "ids     = modelset_df['id']\n",
    "labels  = modelset_df['category']\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(ids, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features\n",
    "\n",
    "A neural networks takes an input a numerical vector. So, we need a way to encode a model into a vector. A simple way is to use a TF-IDF encoding. Essentially, [TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a measure of the relevance of a word by comparing the number of times that a word appears in a document with respect to the number of documents in which the word appears. \n",
    "\n",
    "To apply TF-IDF, the first thing that we need to do is to extract a textual representation of each model. We use the `txt_file` method to obtain the path to the text file associated with a given model. This is a feature provided by ModelSet: for each model there is already `.txt` which contains its 1-gram (i.e., the values of the string attributes).  \n",
    "\n",
    "Then, we can easily compute the TF-IDF using scikit-learn. The `X` and `T` matrices contain one row per model with a number of columns equals to the number of words in the models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "train_filenames = [ dataset.txt_file(id) for id in train_X ]\n",
    "test_filenames  = [ dataset.txt_file(id) for id in test_X ]\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='filename', min_df = 2)\n",
    "X = vectorizer.fit_transform(train_filenames)\n",
    "T = vectorizer.transform(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output of the TF-IDF vectorization is a large matrix with len(train_X) rows and as many columns as words in the vocabulary\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We use a neural network with one hidden layer as our model. This is straightforward with scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#input_layer = X.shape[1]\n",
    "clf = MLPClassifier(solver='adam', learning_rate_init=0.01, hidden_layer_sizes=(64), random_state=1)\n",
    "clf.fit(X, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we evaluate the results obtained in the training set. In particular, we focus on the accuracy (the fraction of correctly classified examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = clf.predict(X)\n",
    "# print(confusion_matrix(train_y, predict_train))\n",
    "train_report = classification_report(train_y, predict_train, output_dict = True)\n",
    "print(\"Training accuracy: \", train_report['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we evaluate the classifier over the test set. As can be seen the results are good, and in principle, we can assume that our model is ok and we can use it in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = clf.predict(T)\n",
    "test_report = classification_report(test_y, predict_test, output_dict = True)\n",
    "print(\"Test accuracy: \", test_report['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
